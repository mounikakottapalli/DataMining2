{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/rt_reviews.csv\", encoding='ISO-8859-1')\n",
        "df.head()\n",
        "\n",
        "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "train_size = int(0.8 * len(df))\n",
        "dev_size = int(0.1 * len(df))\n",
        "test_size = len(df) - train_size - dev_size\n",
        "\n",
        "# Splitting the datasets\n",
        "train_df = df_shuffled[:train_size]\n",
        "dev_df = df_shuffled[train_size : train_size + dev_size]\n",
        "test_df = df_shuffled[train_size + dev_size :]\n",
        "\n",
        "\n",
        "word_counts = Counter()\n",
        "for review in train_df['Review']:\n",
        "    tokens = review.lower().split()\n",
        "    word_counts.update(tokens)\n",
        "\n"
      ],
      "metadata": {
        "id": "AInZJIHHdDWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build a vocabulary of words\n",
        "word_count = {}\n",
        "for review in df_train['Review']:\n",
        "    words = review.lower().split()\n",
        "    for word in words:\n",
        "        if word in word_count:\n",
        "            word_count[word] += 1\n",
        "        else:\n",
        "            word_count[word] = 1\n",
        "\n",
        "vocabulary = []\n",
        "reverse_index = {}\n",
        "for i, (word, count) in enumerate(word_count.items()):\n",
        "    if count >= 5:\n",
        "        vocabulary.append(word)\n",
        "        reverse_index[word] = i\n"
      ],
      "metadata": {
        "id": "Oj3q0MFtkE9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the probability of occurrence and conditional probability of each word\n",
        "num_documents = len(df_train)\n",
        "num_positive_documents = len(df_train[df_train['Freshness'] == 'Fresh'])\n",
        "num_negative_documents = len(df_train[df_train['Freshness'] == 'Rotten'])\n",
        "\n",
        "word_prob = {}\n",
        "word_given_positive_prob = {}\n",
        "word_given_negative_prob = {}\n",
        "\n",
        "for word in vocabulary:\n",
        "    # probability of occurrence\n",
        "    num_documents_containing_word = sum(df_train['Review'].apply(lambda x: word in x.lower().split()))\n",
        "    word_prob[word] = num_documents_containing_word / num_documents\n",
        "    \n",
        "    # conditional probability given positive sentiment\n",
        "    num_positive_documents_containing_word = sum(df_train[df_train['Freshness'] == 'Fresh']['Review'].apply(lambda x: word in x.lower().split()))\n",
        "    word_given_positive_prob[word] = num_positive_documents_containing_word / num_positive_documents\n",
        "    \n",
        "    # conditional probability given negative sentiment\n",
        "    num_negative_documents_containing_word = sum(df_train[df_train['Freshness'] == 'Rotten']['Review'].apply(lambda x: word in x.lower().split()))\n",
        "    word_given_negative_prob[word] = num_negative_documents_containing_word / num_negative_documents\n"
      ],
      "metadata": {
        "id": "_R0eqVX5kPMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implement NBC to classify the reviews in the development set\n",
        "def classify(review):\n",
        "    log_prob_positive = 0\n",
        "    log_prob_negative = 0\n",
        "    \n",
        "    for word in review.lower().split():\n",
        "        if word in vocabulary:\n",
        "            log_prob_positive += np.log(word_given_positive_prob[word])\n",
        "            log_prob_negative += np.log(word_given_negative_prob[word])\n",
        "    \n",
        "    log_prob_positive += np.log(num_positive_documents / num_documents)\n",
        "    log_prob_negative += np.log(num_negative_documents / num_documents)\n",
        "    \n",
        "    if log_prob_positive > log_prob_negative:\n",
        "        return 'Fresh'\n",
        "    else:\n",
        "        return 'Rotten'\n",
        "\n",
        "df_dev['NBC Prediction'] = df_dev['Review'].apply(classify)\n"
      ],
      "metadata": {
        "id": "h2n0HaIykYUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the accuracy of the NBC model on the development set\n",
        "accuracy = sum(df_dev['NBC Prediction'] == df_dev['Freshness']) / len(df_dev) * 100\n",
        "print(f\"Accuracy on development set: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "1DWXocIikgJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implement Laplace smoothing to compare the effect of smoothing\n",
        "def classify_smoothed(review, alpha):\n",
        "    log_prob_positive = 0\n",
        "    log_prob_negative = 0\n",
        "    \n",
        "    for word in review.lower().split():\n",
        "        if word in vocabulary:\n",
        "            log_prob_positive += np.log((word_given_positive_prob[word] * num_positive_documents + alpha) / (num_positive_documents + alpha * len(vocabulary)))\n",
        "            log_prob_negative += np.log((word_given_negative_prob[word] * num_negative_documents + alpha) / (num_negative_documents + alpha * len(vocabulary)))\n",
        "    \n",
        "    log_prob_positive += np.log(num_positive_documents / num_documents)\n",
        "    log_prob_negative += np.log(num_negative_documents / num_documents)\n",
        "    \n",
        "    if log_prob_positive > log_prob_negative:\n",
        "        return 'Fresh'\n",
        "    else:\n",
        "        return 'Rotten'\n",
        "\n",
        "# evaluate the accuracy of NBC with and without smoothing on the development set\n",
        "alphas = [0, 0.1, 0.5, 1, 2, 5, 10, 20, 50]\n",
        "accuracies = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    df_dev['NBC Prediction Smoothed'] = df_dev['Review'].apply(lambda x: classify_smoothed(x, alpha))\n",
        "    accuracy = sum(df_dev['NBC Prediction Smoothed'] == df_dev['Freshness']) / len(df_dev) * 100\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "plt.plot(alphas, accuracies, 'bo-')\n",
        "plt.xlabel('Alpha')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Effect of Laplace smoothing')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2DWtTlRNksfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# identify the top 10 words that predict each class based on conditional probabilities\n",
        "top_positive_words = sorted(word_given_positive_prob, key=word_given_positive_prob.get, reverse=True)[:10]\n",
        "top_negative_words = sorted(word_given_negative_prob, key=word_given_negative_prob.get, reverse=True)[:10]\n",
        "\n",
        "print(f\"Top 10 words that predict positive reviews: {top_positive_words}\")\n",
        "print(f\"Top 10 words that predict negative reviews: {top_negative_words}\")\n"
      ],
      "metadata": {
        "id": "oP911LSWk41M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classify the test set and calculate accuracy\n",
        "correct = 0\n",
        "for review, label in test_set:\n",
        "    predicted_label = classify_review(review, vocab, prior_prob, word_given_positive_prob, word_given_negative_prob, alpha=1.0)\n",
        "    if predicted_label == label:\n",
        "        correct += 1\n",
        "\n",
        "test_accuracy = correct / len(test_set)\n",
        "print(f\"Test accuracy: {test_accuracy}\")\n"
      ],
      "metadata": {
        "id": "Hz-GaVsylC_b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}